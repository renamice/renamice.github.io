<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Neural Networks in JS. | rena</title>
<meta name=keywords content="computer science,AI/ML"><meta name=description content="Blog - Neural Networks in JS

Disclaimer: This is a failed experiment; well, kind of.
&ldquo;Lord God, I have committed a sin.&rdquo;
I have done yet another thing that JS was not truly made for. Or maybe it was. I guess that was a good hook into the story of how I coded a neural networks in JS. And unlike other people&rsquo;s blogs this one is literal. Others, for good reasons, display not only their neural networks but also their algorithms to train them, and also showcase their use-case. Not this one, this one is literal, and is only about the creation of Neural Networks; nothing more, nothing less."><meta name=author content="Rena Mice"><link rel=canonical href=https://renamice.github.io/posts/nn_in_js/><link crossorigin=anonymous href=/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as=style><link rel=icon href=https://renamice.github.io/assets/favicon/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://renamice.github.io/assets/favicon/favicon16x16.png><link rel=icon type=image/png sizes=32x32 href=https://renamice.github.io/assets/favicon/favicon32x32.png><link rel=apple-touch-icon href=https://renamice.github.io/assets/favicon/apple_touch_icon.png><link rel=mask-icon href=https://renamice.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://renamice.github.io/posts/nn_in_js/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:url" content="https://renamice.github.io/posts/nn_in_js/"><meta property="og:site_name" content="rena"><meta property="og:title" content="Neural Networks in JS."><meta property="og:description" content="Blog - Neural Networks in JS Disclaimer: This is a failed experiment; well, kind of.
“Lord God, I have committed a sin.”
I have done yet another thing that JS was not truly made for. Or maybe it was. I guess that was a good hook into the story of how I coded a neural networks in JS. And unlike other people’s blogs this one is literal. Others, for good reasons, display not only their neural networks but also their algorithms to train them, and also showcase their use-case. Not this one, this one is literal, and is only about the creation of Neural Networks; nothing more, nothing less."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-03-11T13:41:37+05:45"><meta property="article:modified_time" content="2025-03-11T13:41:37+05:45"><meta property="article:tag" content="Computer Science"><meta property="article:tag" content="AI/ML"><meta name=twitter:card content="summary"><meta name=twitter:title content="Neural Networks in JS."><meta name=twitter:description content="Blog - Neural Networks in JS

Disclaimer: This is a failed experiment; well, kind of.
&ldquo;Lord God, I have committed a sin.&rdquo;
I have done yet another thing that JS was not truly made for. Or maybe it was. I guess that was a good hook into the story of how I coded a neural networks in JS. And unlike other people&rsquo;s blogs this one is literal. Others, for good reasons, display not only their neural networks but also their algorithms to train them, and also showcase their use-case. Not this one, this one is literal, and is only about the creation of Neural Networks; nothing more, nothing less."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://renamice.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Neural Networks in JS.","item":"https://renamice.github.io/posts/nn_in_js/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Neural Networks in JS.","name":"Neural Networks in JS.","description":"Blog - Neural Networks in JS Disclaimer: This is a failed experiment; well, kind of.\n\u0026ldquo;Lord God, I have committed a sin.\u0026rdquo;\nI have done yet another thing that JS was not truly made for. Or maybe it was. I guess that was a good hook into the story of how I coded a neural networks in JS. And unlike other people\u0026rsquo;s blogs this one is literal. Others, for good reasons, display not only their neural networks but also their algorithms to train them, and also showcase their use-case. Not this one, this one is literal, and is only about the creation of Neural Networks; nothing more, nothing less.\n","keywords":["computer science","AI/ML"],"articleBody":"Blog - Neural Networks in JS Disclaimer: This is a failed experiment; well, kind of.\n“Lord God, I have committed a sin.”\nI have done yet another thing that JS was not truly made for. Or maybe it was. I guess that was a good hook into the story of how I coded a neural networks in JS. And unlike other people’s blogs this one is literal. Others, for good reasons, display not only their neural networks but also their algorithms to train them, and also showcase their use-case. Not this one, this one is literal, and is only about the creation of Neural Networks; nothing more, nothing less.\nAll this started as a stupid comment from my fried Sulav, “how about doing AI/ML in JS?” He is a great guy who works primarily in JS, so I suppose this was a case of natural instinct for someone to choose the tools which they are already most familiar with. Initially, I brushed it off as a stupid idea; but the more I thought about it, the more funny it seemed.\nSo, off I went trying to do just that.\nNeurons class Neuron { constructor(inputSize) { this.weights = Array.from({ length: inputSize }, randomWeight); this.bias = randomWeight(); } compute_sum(inputs) { let total = 0; for (let i = 0; i \u003c this.weights.length; i++) { total += this.weights[i] * inputs[i]; } total += this.bias; return this.activation(total); // makeshift activation function for now } activation(result) { return 1 / (1 + 2.718281 ** -result); } } The constructor for this class just takes in the number of inputs it is supposed to take in, and assigns random weights to each of them.\nThe compute_sum is also very basic. It just adds up the multiples of each input with it’s respective weight.\n$$ \\begin{align} \\text{compute sum} \u0026= \\sum_{i=0}^n{w_i x_i} + bias \\ \\text{where, } x \u0026= \\text{input vector} \\ w \u0026= \\text{weight vector} \\end{align} $$\nThe activation function for this test case is a sigmoid function[1].\n$$ \\sigma(x) = \\frac{1}{1+e^{-x}} $$\nI thought putting up such formulas would make this very basic blog a bit “fancy”.\nLayer class Layer { constructor(inputSize, neuronCount) { this.neurons = Array.from( { length: neuronCount }, () =\u003e new Neuron(inputSize), ); } forward(input_vector) { return this.neurons.map((neuron) =\u003e neuron.compute_sum(input_vector)); } } Layer is just a compound data-type built up of Neurons. It is also responsible for passing outputs from the previous layer as inputs to its element neurons.\nThe constructor just takes in how long the input layer will be and the number of Neurons it is supposed to house. Then it just initializes each neuron within it.\nThe forward() functions is responsible for passing the input vector to each of the neuron within itself.\nNeural Network class NeuralNetwork { constructor(layerSizes) { this.layers = []; // list for (let i = 1; i \u003c layerSizes.length; i++) { this.layers.push(new Layer(layerSizes[i - 1], layerSizes[i])); } } forward_propagation(input_vector) { let input = input_vector; for (let i = 0; i \u003c this.layers.length; i++) { input = this.layers[i].forward(input); } return input; } } This is yet another abstraction over the previously written code. One could as well go about coding the neural Network by hand (something I did while testing if the previous definitions worked or not). This practice is feasible for small networks, but when you want to create large systems, you want something that will handle things such as making sure the lengths of input vector is equal of the length of the previous output vector.\nThe neural network object takes in an array of numbers. Each number is treated as the length of the Layer vector for it’s respective layer number.\nThis way, it bypasses the need to define input-layer, hidden-layer, output-layer as three different variables; it just works with whatever single input you pass in it.\nYou might question (if anyone’s even reading this that is) why not create something out of this then?/ The answer is pretty simple: JS sucks, or either I suck at JS; …probably the latter one.\nThe most annoying thing with using JS was that it doesn’t give you an error when an computation produces a NaN and does not warn you when you compute with NaN. This was a major source of issues when I tried implement some basic training algorithms.\nAnd as of now, I do not know much about the subject matter. It is something that I will be learning as I move ahead.\nNone the less, I will come back to this topic with a language which is much better equipped with tools to tackle the problems. Using JS was just a random fun experiment which I consider to have failed, but in a fun way.\nReferences [1] Wikipedia, Sigmoid function\n","wordCount":"787","inLanguage":"en","datePublished":"2025-03-11T13:41:37+05:45","dateModified":"2025-03-11T13:41:37+05:45","author":{"@type":"Person","name":"Rena Mice"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://renamice.github.io/posts/nn_in_js/"},"publisher":{"@type":"Organization","name":"rena","logo":{"@type":"ImageObject","url":"https://renamice.github.io/assets/favicon/favicon.ico"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://renamice.github.io/ accesskey=h title="rena (Alt + H)">rena</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://renamice.github.io/archive/ title=Archive><span>Archive</span></a></li><li><a href=https://renamice.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://renamice.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://renamice.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Neural Networks in JS.</h1><div class=post-meta><span title='2025-03-11 13:41:37 +0545 +0545'>March 11, 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;787 words&nbsp;·&nbsp;Rena Mice</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#neurons>Neurons</a></li><li><a href=#layer>Layer</a></li><li><a href=#neural-network>Neural Network</a></li></ul></nav></div></details></div><div class=post-content><h1 id=blog---neural-networks-in-js>Blog - Neural Networks in JS<a hidden class=anchor aria-hidden=true href=#blog---neural-networks-in-js>#</a></h1><hr><p><strong>Disclaimer</strong>: This is a <em>failed</em> experiment; well, kind of.</p><p>&ldquo;Lord God, I have committed a sin.&rdquo;<br>I have done yet another thing that JS was not truly made for. Or maybe it was. I guess that was a good hook into the story of how I coded a neural networks in JS. And unlike other people&rsquo;s blogs this one is literal. Others, for good reasons, display not only their neural networks but also their algorithms to train them, and also showcase their use-case. Not this one, this one is literal, and is only about the creation of Neural Networks; nothing more, nothing less.</p><p>All this started as a stupid comment from my fried <a href=https://sulavgautam.vercel.app/>Sulav</a>, &ldquo;how about doing AI/ML in JS?&rdquo; He is a great guy who works primarily in JS, so I suppose this was a case of natural instinct for someone to choose the tools which they are already most familiar with. Initially, I brushed it off as a stupid idea; but the more I thought about it, the more funny it seemed.<br>So, off I went trying to do just that.</p><h2 id=neurons>Neurons<a hidden class=anchor aria-hidden=true href=#neurons>#</a></h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-JS data-lang=JS><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>Neuron</span> {
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>constructor</span>(<span style=color:#a6e22e>inputSize</span>) {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>weights</span> <span style=color:#f92672>=</span> Array.<span style=color:#a6e22e>from</span>({ <span style=color:#a6e22e>length</span><span style=color:#f92672>:</span> <span style=color:#a6e22e>inputSize</span> }, <span style=color:#a6e22e>randomWeight</span>);
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>bias</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>randomWeight</span>();
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>compute_sum</span>(<span style=color:#a6e22e>inputs</span>) {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> <span style=color:#a6e22e>total</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>let</span> <span style=color:#a6e22e>i</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; <span style=color:#a6e22e>i</span> <span style=color:#f92672>&lt;</span> <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>weights</span>.<span style=color:#a6e22e>length</span>; <span style=color:#a6e22e>i</span><span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>      <span style=color:#a6e22e>total</span> <span style=color:#f92672>+=</span> <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>weights</span>[<span style=color:#a6e22e>i</span>] <span style=color:#f92672>*</span> <span style=color:#a6e22e>inputs</span>[<span style=color:#a6e22e>i</span>];
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>total</span> <span style=color:#f92672>+=</span> <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>bias</span>;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>activation</span>(<span style=color:#a6e22e>total</span>); <span style=color:#75715e>// makeshift activation function for now
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>  }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>activation</span>(<span style=color:#a6e22e>result</span>) {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>1</span> <span style=color:#f92672>/</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>+</span> <span style=color:#ae81ff>2.718281</span> <span style=color:#f92672>**</span> <span style=color:#f92672>-</span><span style=color:#a6e22e>result</span>);
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>The constructor for this class just takes in the number of inputs it is supposed to take in, and assigns random weights to each of them.</p><p>The compute_sum is also very basic. It just adds up the multiples of each input with it&rsquo;s respective weight.</p><p>$$
\begin{align}
\text{compute sum} &= \sum_{i=0}^n{w_i x_i} + bias \
\text{where, } x &= \text{input vector} \
w &= \text{weight vector}
\end{align}
$$</p><p>The activation function for this test case is a sigmoid function[1].</p><p>$$
\sigma(x) = \frac{1}{1+e^{-x}}
$$</p><blockquote><p>I thought putting up such formulas would make this very basic blog a bit <em>&ldquo;fancy&rdquo;</em>.</p></blockquote><h2 id=layer>Layer<a hidden class=anchor aria-hidden=true href=#layer>#</a></h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-JS data-lang=JS><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>Layer</span> {
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>constructor</span>(<span style=color:#a6e22e>inputSize</span>, <span style=color:#a6e22e>neuronCount</span>) {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>neurons</span> <span style=color:#f92672>=</span> Array.<span style=color:#a6e22e>from</span>(
</span></span><span style=display:flex><span>      { <span style=color:#a6e22e>length</span><span style=color:#f92672>:</span> <span style=color:#a6e22e>neuronCount</span> },
</span></span><span style=display:flex><span>      () =&gt; <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>Neuron</span>(<span style=color:#a6e22e>inputSize</span>),
</span></span><span style=display:flex><span>    );
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>forward</span>(<span style=color:#a6e22e>input_vector</span>) {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>neurons</span>.<span style=color:#a6e22e>map</span>((<span style=color:#a6e22e>neuron</span>) =&gt; <span style=color:#a6e22e>neuron</span>.<span style=color:#a6e22e>compute_sum</span>(<span style=color:#a6e22e>input_vector</span>));
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Layer is just a compound data-type built up of Neurons. It is also responsible for passing outputs from the previous layer as inputs to its element neurons.<br>The constructor just takes in how long the input layer will be and the number of Neurons it is supposed to house. Then it just initializes each neuron within it.</p><p>The <code>forward()</code> functions is responsible for passing the input vector to each of the neuron within itself.</p><h2 id=neural-network>Neural Network<a hidden class=anchor aria-hidden=true href=#neural-network>#</a></h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-JS data-lang=JS><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>NeuralNetwork</span> {
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>constructor</span>(<span style=color:#a6e22e>layerSizes</span>) {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>layers</span> <span style=color:#f92672>=</span> []; <span style=color:#75715e>// list&lt;Layer&gt;
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>let</span> <span style=color:#a6e22e>i</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>; <span style=color:#a6e22e>i</span> <span style=color:#f92672>&lt;</span> <span style=color:#a6e22e>layerSizes</span>.<span style=color:#a6e22e>length</span>; <span style=color:#a6e22e>i</span><span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>      <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>layers</span>.<span style=color:#a6e22e>push</span>(<span style=color:#66d9ef>new</span> <span style=color:#a6e22e>Layer</span>(<span style=color:#a6e22e>layerSizes</span>[<span style=color:#a6e22e>i</span> <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>], <span style=color:#a6e22e>layerSizes</span>[<span style=color:#a6e22e>i</span>]));
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>forward_propagation</span>(<span style=color:#a6e22e>input_vector</span>) {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> <span style=color:#a6e22e>input</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>input_vector</span>;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>let</span> <span style=color:#a6e22e>i</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; <span style=color:#a6e22e>i</span> <span style=color:#f92672>&lt;</span> <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>layers</span>.<span style=color:#a6e22e>length</span>; <span style=color:#a6e22e>i</span><span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>      <span style=color:#a6e22e>input</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>layers</span>[<span style=color:#a6e22e>i</span>].<span style=color:#a6e22e>forward</span>(<span style=color:#a6e22e>input</span>);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> <span style=color:#a6e22e>input</span>;
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>This is yet another abstraction over the previously written code. One could as well go about coding the neural Network by hand (something I did while testing if the previous definitions worked or not). This practice is feasible for small networks, but when you want to create large systems, you want something that will handle things such as making sure the lengths of input vector is equal of the length of the previous output vector.</p><p>The neural network object takes in an array of numbers. Each number is treated as the length of the Layer vector for it&rsquo;s respective layer number.<br>This way, it bypasses the need to define input-layer, hidden-layer, output-layer as three different variables; it just works with whatever single input you pass in it.</p><hr><p>You might question (if anyone&rsquo;s even reading this that is) why not create something out of this then?/
The answer is pretty simple: JS sucks, or either I suck at JS; &mldr;probably the latter one.</p><p>The most annoying thing with using JS was that it doesn&rsquo;t give you an error when an computation produces a <code>NaN</code> and does not warn you when you compute with <code>NaN</code>. This was a major source of issues when I tried implement some basic training algorithms.<br>And as of now, I do not know much about the subject matter. It is something that I will be learning as I move ahead.</p><p>None the less, I will come back to this topic with a language which is much better equipped with tools to tackle the problems. Using JS was just a random fun experiment which I consider to have failed, but in a fun way.</p><hr><h1 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h1><p>[1] Wikipedia, <a href=https://en.wikipedia.org/wiki/Sigmoid_function><em>Sigmoid function</em></a></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://renamice.github.io/tags/computer-science/>Computer Science</a></li><li><a href=https://renamice.github.io/tags/ai/ml/>AI/ML</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://renamice.github.io/>rena</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>